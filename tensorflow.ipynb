{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the tensorflow lib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "print(\"Tensorflow version:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2904 - accuracy: 0.9153\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1421 - accuracy: 0.9576\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1065 - accuracy: 0.9676\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0871 - accuracy: 0.9736\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0718 - accuracy: 0.9772\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0663 - accuracy: 0.9787\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0591 - accuracy: 0.9805\n",
      "Epoch 8/10\n",
      "1351/1875 [====================>.........] - ETA: 1s - loss: 0.0521 - accuracy: 0.9831"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "#building a model to train the data from the dataset of mnist\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)), #different layer in the model and there function\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "predictions =  model(x_train[:1]).numpy() \n",
    "\n",
    "# print(predictions)\n",
    "\n",
    "tf.nn.softmax(predictions).numpy()\n",
    "\n",
    "#defining a loss function\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "loss_fn(y_train[:1],predictions).numpy()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "loss=loss_fn,\n",
    "metrics=[\"accuracy\"]) #compiling the model using the optimize and the loss_fn and using accuracy to measure the model performance .\n",
    "\n",
    "model.fit(x_train,y_train, epochs=10) #adjust the parameter using .fit method to minimize the lose .\n",
    "\n",
    "model.evaluate(x_test,y_test, verbose=2)\n",
    "\n",
    "#If you want to return the probability then just wrap the model into the softmax using the sequential\n",
    "\n",
    "predicational_model= tf.keras.models.Sequential([\n",
    "    model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "prdeicational_model(x_text[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
