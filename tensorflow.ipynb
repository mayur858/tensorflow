{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the tensorflow lib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "print(\"Tensorflow version:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2950 - accuracy: 0.9144\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1422 - accuracy: 0.9582\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1063 - accuracy: 0.9667\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0879 - accuracy: 0.9729\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0752 - accuracy: 0.9759\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0656 - accuracy: 0.9788\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0580 - accuracy: 0.9817\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0506 - accuracy: 0.9836\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0461 - accuracy: 0.9852\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0451 - accuracy: 0.9855\n",
      "313/313 - 1s - loss: 0.0669 - accuracy: 0.9804 - 579ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[2.85638286e-08, 1.95787928e-10, 4.03944007e-08, 8.41915840e-04,\n",
       "        3.48601898e-14, 1.07325462e-07, 2.22681124e-16, 9.99156952e-01,\n",
       "        8.84912197e-08, 9.00264354e-07],\n",
       "       [1.17096068e-12, 1.00187353e-05, 9.99989867e-01, 2.25705588e-08,\n",
       "        1.20501404e-21, 9.85738069e-08, 1.72062961e-10, 3.68945019e-17,\n",
       "        4.31306602e-10, 1.01022114e-19],\n",
       "       [2.48535486e-08, 9.99935269e-01, 5.73328816e-06, 2.61679105e-07,\n",
       "        8.40413179e-07, 1.15464232e-07, 1.56818919e-06, 2.26067787e-05,\n",
       "        3.34338256e-05, 5.64139002e-09],\n",
       "       [9.99931574e-01, 1.10507263e-11, 7.79330276e-06, 3.06501491e-08,\n",
       "        2.30467467e-09, 2.69119550e-06, 4.97535439e-05, 2.58340094e-07,\n",
       "        2.31905301e-06, 5.55720680e-06],\n",
       "       [6.48442381e-07, 1.48435290e-12, 5.66667541e-06, 2.71728778e-10,\n",
       "        9.98916984e-01, 8.24276558e-09, 9.06331223e-08, 1.37548022e-05,\n",
       "        9.21715966e-08, 1.06276711e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "#building a model to train the data from the dataset of mnist\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)), #different layer in the model and there function\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "predictions =  model(x_train[:1]).numpy() \n",
    "\n",
    "# print(predictions)\n",
    "\n",
    "tf.nn.softmax(predictions).numpy()\n",
    "\n",
    "#defining a loss function\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "loss_fn(y_train[:1],predictions).numpy()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "loss=loss_fn,\n",
    "metrics=[\"accuracy\"]) #compiling the model using the optimize and the loss_fn and using accuracy to measure the model performance .\n",
    "\n",
    "model.fit(x_train,y_train, epochs=10) #adjust the parameter using .fit method to minimize the lose .\n",
    "\n",
    "model.evaluate(x_test,y_test, verbose=2)\n",
    "\n",
    "#If you want to return the probability then just wrap the model into the softmax using the sequential\n",
    "\n",
    "predicational_model= tf.keras.models.Sequential([\n",
    "    model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "predicational_model(x_test[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
